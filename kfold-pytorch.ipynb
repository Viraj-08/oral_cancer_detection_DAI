{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7599778,"sourceType":"datasetVersion","datasetId":4423968}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"try:\n    from torchinfo import summary\nexcept:\n    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n    !pip install -q torchinfo\n    from torchinfo import summary","metadata":{"execution":{"iopub.status.busy":"2024-02-11T11:25:38.620474Z","iopub.execute_input":"2024-02-11T11:25:38.621124Z","iopub.status.idle":"2024-02-11T11:25:38.626794Z","shell.execute_reply.started":"2024-02-11T11:25:38.621089Z","shell.execute_reply":"2024-02-11T11:25:38.625557Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport os\nfrom pathlib import Path\nimport re\nimport random\nimport matplotlib.pyplot as plt\nimport math\nimport torch\n\nfrom PIL import Image\nfrom pandas import DataFrame\nfrom typing import Tuple, Dict, List\nfrom torch.utils.data import Dataset, DataLoader\n\n\"\"\"\nContains functions for training and testing a PyTorch model.\n\"\"\"\nfrom torchinfo import summary\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n\nfrom torchvision import datasets, models, transforms\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim","metadata":{"execution":{"iopub.status.busy":"2024-02-11T11:25:38.628691Z","iopub.execute_input":"2024-02-11T11:25:38.629079Z","iopub.status.idle":"2024-02-11T11:25:38.640700Z","shell.execute_reply.started":"2024-02-11T11:25:38.629049Z","shell.execute_reply":"2024-02-11T11:25:38.639750Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"data_path = Path('/kaggle/input/oral-dataset/patches')\ndir_list = os.listdir(data_path)\nprint(\"Files and directories in '\", data_path, \"' :\")\n# prints all files\nprint(dir_list)","metadata":{"execution":{"iopub.status.busy":"2024-02-11T11:25:38.642595Z","iopub.execute_input":"2024-02-11T11:25:38.642950Z","iopub.status.idle":"2024-02-11T11:25:38.652564Z","shell.execute_reply.started":"2024-02-11T11:25:38.642924Z","shell.execute_reply":"2024-02-11T11:25:38.651614Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Files and directories in ' /kaggle/input/oral-dataset/patches ' :\n['sabpatch_parsed_test.csv', 'images', 'sabpatch_parsed_folders.csv']\n","output_type":"stream"}]},{"cell_type":"code","source":"image_dir = data_path / 'images'\ntrain_df = pd.read_csv(data_path/'sabpatch_parsed_folders.csv')\ntrain_ds = train_df[['path','lesion']]\ntest_df = pd.read_csv(data_path/'sabpatch_parsed_test.csv')\ntest_ds = test_df[['path','lesion']]","metadata":{"execution":{"iopub.status.busy":"2024-02-11T11:25:38.653778Z","iopub.execute_input":"2024-02-11T11:25:38.654090Z","iopub.status.idle":"2024-02-11T11:25:38.671264Z","shell.execute_reply.started":"2024-02-11T11:25:38.654065Z","shell.execute_reply":"2024-02-11T11:25:38.670048Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"ALPHA = 0.00005 ## Learning Rate\nEPOCH = 5  ## Epochs\nBATCH_SIZE = 32\nK_FOLDS = 5\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nMEAN = [0.485, 0.456, 0.406]\nSTD = [0.229, 0.224, 0.225]","metadata":{"execution":{"iopub.status.busy":"2024-02-11T11:25:38.673327Z","iopub.execute_input":"2024-02-11T11:25:38.673616Z","iopub.status.idle":"2024-02-11T11:25:38.679259Z","shell.execute_reply.started":"2024-02-11T11:25:38.673593Z","shell.execute_reply":"2024-02-11T11:25:38.678251Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Write a custom dataset class (inherits from torch.utils.data.Dataset)\nclass ImageFolderCustom(Dataset):\n\n    # 1. Initialize with a targ_dir and transform (optional) parameter\n    def __init__(self,\n                 targ_dir: str,\n                 path_df: DataFrame,\n                 transform=None) -> None:\n\n        # Get all image paths, classes\n        self.img_df = path_df\n\n        # Set all images to proper path\n        self.img_df['path'] = self.check_path(targ_dir)\n\n        self.paths = list(self.img_df['path'])\n\n        # Setup transforms\n        self.transform = transform\n\n        self.classes, self.class_to_idx = self.find_classes()\n\n    # 2. check if its already in proper format\n    def check_path(self,\n                   targ_dir: str) -> DataFrame:\n        if str(targ_dir) in self.img_df.iloc[0,0]:\n            return self.img_df['path'].astype('string')\n        else:\n            return str(targ_dir)+ '/' +  self.img_df['path'].astype('string')\n\n    # 3. Make function to load images\n    def load_image(self,\n                   index: int) -> Image.Image:\n        \"Opens an image via a path and returns it.\"\n        image_path = self.img_df.iloc[index, 0]\n        return Image.open(image_path)\n\n    # 4. Overwrite the __len__() method (optional but recommended for subclasses of torch.utils.data.Dataset)\n    def __len__(self) -> int:\n        \"Returns the total number of samples.\"\n        return self.img_df.shape[0]\n\n    # 5. Overwrite the __getitem__() method (required for subclasses of torch.utils.data.Dataset)\n    def __getitem__(self,\n                    index: int) -> Tuple[torch.Tensor, int]:\n        \"Returns one sample of data, data and label (X, y).\"\n        img = self.load_image(index)\n        class_name  = self.img_df.iloc[index, 1] # expects path in data_folder/class_name/image.jpeg\n        class_idx = self.class_to_idx[class_name]\n\n        # Transform if necessary\n        if self.transform:\n            return self.transform(img), class_idx # return data, label (X, y)\n        else:\n            return img, class_idx # return data, label (X, y)\n\n\n    def find_classes(self) -> Tuple[List[str], Dict[str, int]]:\n\n        col = self.img_df.columns\n        # 1. Get the class names by scanning the target directory\n        classes = sorted(self.img_df[col[1]].unique())\n\n        # 2. Raise an error if class names not found\n        if not classes:\n            raise FileNotFoundError(f\"Couldn't find any classes.\")\n\n        # 3. Create a dictionary of index labels (computers prefer numerical rather than string labels)\n        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n        return classes, class_to_idx","metadata":{"execution":{"iopub.status.busy":"2024-02-11T11:25:38.680663Z","iopub.execute_input":"2024-02-11T11:25:38.681043Z","iopub.status.idle":"2024-02-11T11:25:38.696475Z","shell.execute_reply.started":"2024-02-11T11:25:38.681009Z","shell.execute_reply":"2024-02-11T11:25:38.695434Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"manual_transforms = transforms.Compose([\n        transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n        transforms.ToTensor(), # 2. Turn image values to between 0 & 1\n        transforms.Normalize(mean = MEAN, # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n                         std = STD)\n    ])\n\n\n\n    # test_transforms = transforms.Compose([\n    #     #transforms.Resize((64, 64)),\n    #     transforms.ToTensor(),\n    # ])\n\n\ntrain_data = ImageFolderCustom(targ_dir = image_dir,\n                                          path_df = train_ds,\n                                          transform= manual_transforms)\n\ntest_data = ImageFolderCustom(targ_dir = image_dir,\n                                          path_df = test_ds,\n                                          transform= manual_transforms)\n\nclasses, class_to_idx = train_data.find_classes()","metadata":{"execution":{"iopub.status.busy":"2024-02-11T11:25:38.806529Z","iopub.execute_input":"2024-02-11T11:25:38.806908Z","iopub.status.idle":"2024-02-11T11:25:38.825369Z","shell.execute_reply.started":"2024-02-11T11:25:38.806878Z","shell.execute_reply":"2024-02-11T11:25:38.823921Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/1968766816.py:14: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.img_df['path'] = self.check_path(targ_dir)\n","output_type":"stream"}]},{"cell_type":"code","source":"model = models.resnet50(pretrained=True).to(device)\n\n# for param in model.parameters():\n#     param.requires_grad = False\n\nmodel.fc = nn.Sequential(\n               nn.Linear(2048, 128),\n               nn.ReLU(inplace=True),\n               nn.Linear(128, 3)).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-11T11:25:38.827424Z","iopub.execute_input":"2024-02-11T11:25:38.827743Z","iopub.status.idle":"2024-02-11T11:25:39.478916Z","shell.execute_reply.started":"2024-02-11T11:25:38.827717Z","shell.execute_reply":"2024-02-11T11:25:39.477926Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, ConcatDataset\nfrom torchvision import transforms\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\ndef reset_weights(m):\n  '''\n    Try resetting model weights to avoid\n    weight leakage.\n  '''\n  for layer in m.children():\n    if hasattr(layer, 'reset_parameters'):\n#         print(f'Reset trainable parameters of layer = {layer}')\n        layer.reset_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-02-11T11:25:39.480341Z","iopub.execute_input":"2024-02-11T11:25:39.480733Z","iopub.status.idle":"2024-02-11T11:25:39.487498Z","shell.execute_reply.started":"2024-02-11T11:25:39.480692Z","shell.execute_reply":"2024-02-11T11:25:39.486425Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss(reduction='sum') # computes the cross entropy loss between input logits and target.\n\noptimizer = torch.optim.Adam(model.parameters(), lr = ALPHA)","metadata":{"execution":{"iopub.status.busy":"2024-02-11T11:25:39.489869Z","iopub.execute_input":"2024-02-11T11:25:39.490308Z","iopub.status.idle":"2024-02-11T11:25:39.501379Z","shell.execute_reply.started":"2024-02-11T11:25:39.490267Z","shell.execute_reply":"2024-02-11T11:25:39.500200Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model,device,dataloader,loss_fn,optimizer):\n    train_loss,train_correct=0.0,0\n    model.train()\n    for images, labels in dataloader:\n\n        images,labels = images.to(device),labels.to(device)\n        optimizer.zero_grad()\n        output = model(images)\n        loss = loss_fn(output,labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item() * images.size(0)\n        scores, predictions = torch.max(output.data, 1)\n        train_correct += (predictions == labels).sum().item()\n\n    return train_loss,train_correct\n\ndef valid_epoch(model,device,dataloader,loss_fn):\n    valid_loss, val_correct = 0.0, 0\n    model.eval()\n    with torch.no_grad():\n        for images, labels in dataloader:\n            images,labels = images.to(device),labels.to(device)\n            output = model(images)\n            loss=loss_fn(output,labels)\n            valid_loss+=loss.item()*images.size(0)\n            scores, predictions = torch.max(output.data,1)\n            val_correct+=(predictions == labels).sum().item()\n\n    return valid_loss,val_correct","metadata":{"execution":{"iopub.status.busy":"2024-02-11T11:25:39.503113Z","iopub.execute_input":"2024-02-11T11:25:39.503469Z","iopub.status.idle":"2024-02-11T11:25:39.514526Z","shell.execute_reply.started":"2024-02-11T11:25:39.503442Z","shell.execute_reply":"2024-02-11T11:25:39.513553Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"dataset = ConcatDataset([train_data, test_data])\nlabels = [t[1] for t in dataset]","metadata":{"execution":{"iopub.status.busy":"2024-02-11T11:25:39.515754Z","iopub.execute_input":"2024-02-11T11:25:39.517938Z","iopub.status.idle":"2024-02-11T11:26:27.063253Z","shell.execute_reply.started":"2024-02-11T11:25:39.517896Z","shell.execute_reply":"2024-02-11T11:26:27.062275Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"history = {'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n\n# Define the K-fold Cross Validator\nkfold =  StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n\n  # Start print\nprint('--------------------------------')\n\n# K-fold Cross Validation model evaluation\nfor fold, (train_ids, test_ids) in enumerate(kfold.split(dataset, labels)):\n    print('Fold {}'.format(fold + 1))\n\n    # Sample elements randomly from a given list of ids, no replacement.\n    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n    \n    # Define data loaders for training and testing data in this fold\n    trainloader = torch.utils.data.DataLoader(\n                      dataset, \n                      batch_size=32, sampler=train_subsampler)\n    testloader = torch.utils.data.DataLoader(\n                      dataset,\n                      batch_size=32, sampler=test_subsampler)\n    \n    \n    model.to(device)\n    optimizer = optim.Adam(model.parameters(), lr=ALPHA)\n\n    for epoch in range(EPOCH):\n        train_loss, train_correct=train_epoch(model,device,trainloader, loss_fn,optimizer)\n        test_loss, test_correct=valid_epoch(model,device,testloader, loss_fn)\n\n        train_loss = train_loss / len(trainloader.sampler)\n        train_acc = train_correct / len(trainloader.sampler) * 100\n        test_loss = test_loss / len(testloader.sampler)\n        test_acc = test_correct / len(testloader.sampler) * 100\n\n        print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Test Loss:{:.3f} AVG Training Acc {:.2f} % AVG Test Acc {:.2f} %\".format(epoch + 1,\n                                                                                                             EPOCH,\n                                                                                                             train_loss,\n                                                                                                             test_loss,\n                                                                                                             train_acc,\n                                                                                                             test_acc))\n        history['train_loss'].append(train_loss)\n        history['test_loss'].append(test_loss)\n        history['train_acc'].append(train_acc)\n        history['test_acc'].append(test_acc)  ","metadata":{"execution":{"iopub.status.busy":"2024-02-11T11:26:27.065708Z","iopub.execute_input":"2024-02-11T11:26:27.066064Z","iopub.status.idle":"2024-02-11T11:53:27.596111Z","shell.execute_reply.started":"2024-02-11T11:26:27.066036Z","shell.execute_reply":"2024-02-11T11:53:27.595019Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"--------------------------------\nFold 1\nEpoch:1/5 AVG Training Loss:29.065 AVG Test Loss:27.751 AVG Training Acc 55.05 % AVG Test Acc 54.05 %\nEpoch:2/5 AVG Training Loss:26.779 AVG Test Loss:29.186 AVG Training Acc 58.44 % AVG Test Acc 45.42 %\nEpoch:3/5 AVG Training Loss:26.140 AVG Test Loss:25.419 AVG Training Acc 58.84 % AVG Test Acc 62.15 %\nEpoch:4/5 AVG Training Loss:24.450 AVG Test Loss:27.682 AVG Training Acc 62.09 % AVG Test Acc 58.70 %\nEpoch:5/5 AVG Training Loss:24.845 AVG Test Loss:23.524 AVG Training Acc 62.72 % AVG Test Acc 63.61 %\nFold 2\nEpoch:1/5 AVG Training Loss:26.021 AVG Test Loss:29.010 AVG Training Acc 61.00 % AVG Test Acc 55.25 %\nEpoch:2/5 AVG Training Loss:24.532 AVG Test Loss:32.604 AVG Training Acc 63.19 % AVG Test Acc 63.08 %\nEpoch:3/5 AVG Training Loss:23.302 AVG Test Loss:25.836 AVG Training Acc 65.08 % AVG Test Acc 55.51 %\nEpoch:4/5 AVG Training Loss:23.134 AVG Test Loss:24.134 AVG Training Acc 64.02 % AVG Test Acc 63.75 %\nEpoch:5/5 AVG Training Loss:22.582 AVG Test Loss:24.930 AVG Training Acc 66.51 % AVG Test Acc 66.00 %\nFold 3\nEpoch:1/5 AVG Training Loss:22.167 AVG Test Loss:24.826 AVG Training Acc 68.17 % AVG Test Acc 64.81 %\nEpoch:2/5 AVG Training Loss:21.015 AVG Test Loss:20.936 AVG Training Acc 69.24 % AVG Test Acc 72.11 %\nEpoch:3/5 AVG Training Loss:20.472 AVG Test Loss:25.542 AVG Training Acc 72.03 % AVG Test Acc 64.81 %\nEpoch:4/5 AVG Training Loss:19.769 AVG Test Loss:20.227 AVG Training Acc 72.03 % AVG Test Acc 71.18 %\nEpoch:5/5 AVG Training Loss:19.905 AVG Test Loss:20.079 AVG Training Acc 71.23 % AVG Test Acc 71.58 %\nFold 4\nEpoch:1/5 AVG Training Loss:19.709 AVG Test Loss:24.936 AVG Training Acc 72.33 % AVG Test Acc 67.15 %\nEpoch:2/5 AVG Training Loss:18.879 AVG Test Loss:20.214 AVG Training Acc 72.73 % AVG Test Acc 70.21 %\nEpoch:3/5 AVG Training Loss:18.202 AVG Test Loss:20.436 AVG Training Acc 74.19 % AVG Test Acc 68.62 %\nEpoch:4/5 AVG Training Loss:17.819 AVG Test Loss:17.818 AVG Training Acc 75.59 % AVG Test Acc 75.80 %\nEpoch:5/5 AVG Training Loss:17.199 AVG Test Loss:20.673 AVG Training Acc 76.52 % AVG Test Acc 71.81 %\nFold 5\nEpoch:1/5 AVG Training Loss:17.260 AVG Test Loss:15.787 AVG Training Acc 76.72 % AVG Test Acc 78.59 %\nEpoch:2/5 AVG Training Loss:15.402 AVG Test Loss:19.733 AVG Training Acc 78.51 % AVG Test Acc 70.88 %\nEpoch:3/5 AVG Training Loss:15.178 AVG Test Loss:16.073 AVG Training Acc 80.57 % AVG Test Acc 77.93 %\nEpoch:4/5 AVG Training Loss:13.999 AVG Test Loss:17.314 AVG Training Acc 82.13 % AVG Test Acc 75.93 %\nEpoch:5/5 AVG Training Loss:13.503 AVG Test Loss:15.995 AVG Training Acc 82.33 % AVG Test Acc 78.86 %\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\navg_train_loss = np.mean(history['train_loss'])\navg_test_loss = np.mean(history['test_loss'])\navg_train_acc = np.mean(history['train_acc'])\navg_test_acc = np.mean(history['test_acc'])\n\nprint('Performance of {} fold cross validation'.format(K_FOLDS))\nprint(\"Average Training Loss: {:.4f} \\t Average Test Loss: {:.4f} \\t Average Training Acc: {:.3f} \\t Average Test Acc: {:.3f}\".format(avg_train_loss,avg_test_loss,avg_train_acc,avg_test_acc)) ","metadata":{"execution":{"iopub.status.busy":"2024-02-11T11:53:50.968763Z","iopub.execute_input":"2024-02-11T11:53:50.969170Z","iopub.status.idle":"2024-02-11T11:53:50.976491Z","shell.execute_reply.started":"2024-02-11T11:53:50.969137Z","shell.execute_reply":"2024-02-11T11:53:50.975247Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Performance of 5 fold cross validation\nAverage Training Loss: 20.8531 \t Average Test Loss: 22.8266 \t Average Training Acc: 69.651 \t Average Test Acc: 66.711\n","output_type":"stream"}]},{"cell_type":"code","source":"class KFOLD():\n#     wandb.init(\n#     project=\"ressnet50-v1\",\n#     config={\n#             \"epochs\": EPOCH,\n#             \"batch_size\": BATCH_SIZE,\n#             \"lr\": ALPHA,\n#             \"architecture\": \"CNN\",\n#             })\n\n    def __init__(self,\n                 model,\n                 loss_fn,\n                 optimizer,\n                 device,\n                 early_stopping = False):\n\n        self.model = model\n        self.loss_fn = loss_fn\n        self.optimizer = optimizer\n        self.device = device\n\n        self.early_stopping = early_stopping\n        self.counter = 0\n        self.early_stop = False # type: ignore\n        self.best_score = None\n\n#         # Copy your config\n#         self.config = wandb.config\n\n    def check_early_stop(self,\n                   val_loss,\n                   delta,\n                   verbose,\n                   patience):\n\n        score = -val_loss\n        # print(verbose)\n        if self.best_score is None:\n            self.best_score = score\n\n        elif score < self.best_score + delta:\n            self.counter += 1\n\n            if verbose:\n                print(f\"Early stopping counter: {self.counter} out of {patience}\")\n\n            if self.counter >= patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.early_stop = False\n            self.counter = 0\n            \n\n    def train_epoch(self):\n        train_loss,train_correct=0.0,0\n        model.train()\n        for images, labels in self.dataloader:\n\n            images,labels = images.to(device),labels.to(device)\n            optimizer.zero_grad()\n            output = model(images)\n            loss = loss_fn(output,labels)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item() * images.size(0)\n            scores, predictions = torch.max(output.data, 1)\n            train_correct += (predictions == labels).sum().item()\n\n        return train_loss,train_correct\n\n    def valid_epoch(self):\n        valid_loss, val_correct = 0.0, 0\n        model.eval()\n        with torch.no_grad():\n            for images, labels in self.dataloader:\n                images,labels = images.to(device),labels.to(device)\n                output = model(images)\n                loss=loss_fn(output,labels)\n                valid_loss+=loss.item()*images.size(0)\n                scores, predictions = torch.max(output.data,1)\n                val_correct+=(predictions == labels).sum().item()\n\n        return valid_loss,val_correct\n    \n    def train(self,\n              train_dataloader,\n              test_dataloader,\n              epochs=1,\n              k_folds=5,\n              delta = 0,\n              patience = 10,\n              verbose = False):\n\n        self.epochs = epochs\n        self.train_dataloader = train_dataloader\n        self.test_dataloader = test_dataloader\n\n\n        # Create empty results dictionary\n        results = {\"epoch\":[],\n                \"train_loss\": [],\n                \"train_acc\": [],\n                \"test_loss\": [],\n                \"test_acc\": []\n        }\n\n        # Define the K-fold Cross Validator\n        kfold =  StratifiedKFold(n_splits= k_folds, shuffle=True, random_state=42)\n\n        # Sample elements randomly from a given list of ids, no replacement.\n        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n        test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n\n        # Define data loaders for training and testing data in this fold\n        trainloader = torch.utils.data.DataLoader(\n                          dataset, \n                          batch_size = BATCH_SIZE, sampler = train_subsampler)\n        testloader = torch.utils.data.DataLoader(\n                          dataset,\n                          batch_size = BATCH_SIZE, sampler = test_subsampler)\n        \n        \n        self.dataset = ConcatDataset([train_data, test_data])\n        labels = [t[1] for t in dataset]\n\n        # Make sure model on target device\n        self.model.to(self.device)\n\n        # Loop through training and testing steps for a number of epochs\n        print('--------------------------------')\n\n        # K-fold Cross Validation model evaluation\n        for fold, (train_ids, test_ids) in enumerate(kfold.split(self.dataset, labels)):\n            print('Fold {}'.format(fold + 1))\n\n            train_loss, train_acc = self.train_epoch()\n            test_loss, test_acc = self.val_epoch()\n\n            # Print out what's happening\n            print(\n            f\"Epoch: {epoch+1} | \"\n            f\"train_loss: {train_loss:.4f} | \"\n            f\"train_acc: {train_acc:.4f} | \"\n            f\"test_loss: {test_loss:.4f} | \"\n            f\"test_acc: {test_acc:.4f}\"\n            )\n\n            # Update results dictionary\n            results[\"epoch\"].append(epoch+1)\n            results[\"train_loss\"].append(train_loss)\n            results[\"test_loss\"].append(test_loss)\n            results[\"train_acc\"].append(train_acc)\n            results[\"test_acc\"].append(test_acc)\n\n\n\n            if self.early_stopping:\n                self.check_early_stop(test_loss, delta, verbose, patience)\n                if self.early_stop:\n                    print(\"Early Stopping\")\n                    break\n\n        # Mark the run as finished\n#         wandb.finish()\n        # Return the filled results at the end of the epochs\n        return results\n","metadata":{},"execution_count":null,"outputs":[]}]}